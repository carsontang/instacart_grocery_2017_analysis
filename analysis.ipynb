{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Connect to the database\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine('postgresql+psycopg2://ctang:@localhost:5432/ctang', encoding='utf-8') # no password\n",
    "connection = engine.connect()\n",
    "\n",
    "from sqlalchemy import Table, Column, Enum, Boolean, Integer, Numeric, Text, Unicode, ForeignKey\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import relationship, backref\n",
    "\n",
    "Base = declarative_base()\n",
    "\n",
    "class Aisle(Base):\n",
    "    __tablename__ = 'aisles'\n",
    "    \n",
    "    aisle_id = Column('aisle_id', Integer(), autoincrement=True, primary_key=True)\n",
    "    aisle = Column('aisle', Text)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"Aisle(aisle_id={self.aisle_id}, aisle={self.aisle})\".format(self=self)\n",
    "\n",
    "class Department(Base):\n",
    "    __tablename__ = 'departments'\n",
    "    \n",
    "    department_id = Column('department_id', Integer(), autoincrement=True, primary_key=True)\n",
    "    department = Column('department', Text)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"Department(department_id={self.department_id}, department={self.department})\".format(self=self)\n",
    "    \n",
    "class Product(Base):\n",
    "    __tablename__ = 'products'\n",
    "    \n",
    "    product_id = Column('product_id', Integer(), autoincrement=True, primary_key=True)\n",
    "    product_name = Column('product_name', Text())\n",
    "    aisle_id = Column(Integer(), ForeignKey('aisles.aisle_id'))\n",
    "    department_id = Column(Integer(), ForeignKey('departments.department_id'))\n",
    "    \n",
    "    aisle = relationship('Aisle', backref=backref('products', order_by=product_id))\n",
    "    department = relationship('Department', backref=backref('products', order_by=product_id))\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return u\"Product(product_id={self.product_id}, \" \\\n",
    "                \"product_name={self.product_name}, \" \\\n",
    "                \"aisle_id={self.aisle_id}, \" \\\n",
    "                \"department_id={self.department_id})\".format(self=self)\n",
    "\n",
    "class Order(Base):\n",
    "    __tablename__ = 'orders'\n",
    "    \n",
    "    order_id = Column('order_id', Integer(), autoincrement=True, primary_key=True)\n",
    "    user_id = Column('user_id', Integer())\n",
    "    order_eval_set = Column('order_eval_set', Enum('prior', 'train', 'test', name='order_eval_set'))\n",
    "    order_number = Column('order_number', Integer())\n",
    "    order_dow = Column('order_dow', Integer())\n",
    "    order_hour_of_day = Column('order_hour_of_day', Integer())\n",
    "    days_since_prior = Column('days_since_prior', Numeric(), nullable=True)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'Order(order_id={self.order_id}, ' \\\n",
    "                'user_id={self.user_id}, ' \\\n",
    "                'order_eval_set={self.order_eval_set}, ' \\\n",
    "                'order_number={self.order_number}, ' \\\n",
    "                'order_dow={self.order_dow}, ' \\\n",
    "                'order_hour_of_day={self.order_hour_of_day}, ' \\\n",
    "                'days_since_prior={self.days_since_prior})'.format(self=self)\n",
    "\n",
    "class LineItem(Base):\n",
    "    __tablename__ = 'order_products__prior'\n",
    "    \n",
    "    order_id = Column(Integer(), ForeignKey('orders.order_id'), primary_key=True)\n",
    "    product_id = Column(Integer(), ForeignKey('products.product_id'), primary_key=True)\n",
    "    add_to_cart_order = Column('add_to_cart_order', Integer())\n",
    "    reordered = Column('reordered', Boolean())\n",
    "    \n",
    "    order = relationship('Order', backref=backref('line_items', order_by=add_to_cart_order))\n",
    "    department = relationship('Product', backref=backref('line_items', order_by=add_to_cart_order))\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return 'LineItem(order_id={self.order_id}, ' \\\n",
    "                'product_id={self.product_id}, ' \\\n",
    "                'add_to_cart_order={self.add_to_cart_order}, ' \\\n",
    "                'reordered={self.reordered})'.format(self=self)\n",
    "\n",
    "Base.metadata.create_all(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product(product_id=24, product_name=Tri-Vi-SolÂ® Vitamins A-C-and D Supplement Drops for Infants, aisle_id=47, department_id=11)\n"
     ]
    }
   ],
   "source": [
    "# product 24 has a non-ASCII character in it. Print can't understand it.\n",
    "# What's the alternative to print in ASCII?\n",
    "product = session.query(Product).filter(Product.product_id == 24).first()\n",
    "print product.__repr__().encode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       personal care | 6563\n",
      "              snacks | 6264\n",
      "              pantry | 5371\n",
      "           beverages | 4365\n",
      "              frozen | 4007\n",
      "          dairy eggs | 3449\n",
      "           household | 3085\n",
      "        canned goods | 2092\n",
      "     dry goods pasta | 1858\n",
      "             produce | 1684\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy.orm import sessionmaker\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "from sqlalchemy.sql import func, desc, distinct\n",
    "\n",
    "# Top 10 departments with the most product listings\n",
    "for record in session.query(Department.department, func.count().label('product_count')) \\\n",
    "    .join(Product) \\\n",
    "    .group_by(Department.department) \\\n",
    "    .order_by(desc('product_count')) \\\n",
    "    .limit(10):\n",
    "        print \"%20s | %s\" % (record.department, record.product_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Banana | 18726\n",
      "                            Bag of Organic Bananas | 15480\n",
      "                              Organic Strawberries | 10894\n",
      "                              Organic Baby Spinach | 9784\n",
      "                                       Large Lemon | 8135\n",
      "                                   Organic Avocado | 7409\n",
      "                              Organic Hass Avocado | 7293\n",
      "                                      Strawberries | 6494\n",
      "                                             Limes | 6033\n",
      "                               Organic Raspberries | 5546\n"
     ]
    }
   ],
   "source": [
    "# Top N most ordered items\n",
    "for record in session.query(Product.product_name, func.count().label('num_orders')) \\\n",
    "    .join(LineItem) \\\n",
    "    .group_by(Product.product_id) \\\n",
    "    .order_by(desc('num_orders')) \\\n",
    "    .limit(10):\n",
    "        print \"%50s | %s\" % (record.product_name, record.num_orders)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Predicting Days Until Next Order Based on the Current Order\n",
    "\n",
    "Let's build a machine learning model to predict $d = $ days until the next order given only the contents of the current order. We'll represent an order with a feature vector of 0s and 1s. The index of an entry in the vector will correspond to a `product_id`. If the entry is 0, the current order doesn't contain the product. If the entry is 1, the current order contains the product. For example, to represent an order by a customer for `1% Chocolate Milk` and `Kale Apple Greens`, the feature vector would look like\n",
    "\n",
    "$\n",
    "order =\n",
    "\\begin{bmatrix}\n",
    "1 \\\\\n",
    "0 \\\\\n",
    "0 \\\\\n",
    "\\vdots \\\\\n",
    "1 \\\\\n",
    "\\vdots \\\\\n",
    "0 \\\\\n",
    "\\end{bmatrix}\n",
    "\\quad\n",
    "\\begin{array}{l}\n",
    "\\text{1% Chocolate Milk} \\\\\n",
    "\\text{1% Low Fat Cottage Cheese} \\\\\n",
    "\\text{Acacia Fiber Organic Powder} \\\\\n",
    "\\vdots \\\\\n",
    "\\text{Kale Apple Greens} \\\\\n",
    "\\vdots \\\\\n",
    "\\text{Zero Calorie Lemon Lime Twist Soda} \\\\\n",
    "\\end{array}\n",
    "$\n",
    "\n",
    "To represent the entire set of orders using for training our ML model, we'll use a $3421083 \\times 49688$ matrix\n",
    "\n",
    "$\n",
    "orders_{train} =\n",
    "\\overbrace{\n",
    "\\begin{bmatrix}\n",
    "(order_1)^T \\\\\n",
    "(order_2)^T \\\\\n",
    "(order_3)^T \\\\\n",
    "\\vdots \\\\\n",
    "(order_{3,421,083})^T \\\\\n",
    "\\end{bmatrix}\n",
    "}^{49,688}\n",
    "$\n",
    "\n",
    "There are 3,421,083 orders, hence the number of rows. There are 49,688 products, hence the number of columns (or features). Our goal is to learn the weights vector, $\\theta \\in \\mathbb{R}^{49,688 \\times 1}$. Each element of this vector is the weight that each product has in determing how many days later the next order will arrive.\n",
    "\n",
    "Notice that $orders_{train}$ will consist mostly of 0s because the average order contains about 10 out of 49,688 products. This means $orders_{train}$ is a sparse matrix, and perhaps later we can explore taking advantage of this structure to reduce the number of computations to produce $\\theta$.\n",
    "\n",
    "Another thing to notice is that even though we have other information attached to an order such as day of the week, hour of the day, etc., this ML model will assume that those \"features\" don't matter. In the real world, they probably do, but for now, let's ignore them.\n",
    "\n",
    "TODO: Write about the label vector, $y$.\n",
    "\n",
    "Its cost function will be\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "J(\\theta) = \\frac{1}{2} \\sum_{i = 1}^m \\left( h_\\theta (x^{(i)}) - y^{(i)}  \\right)^2\n",
    "\\end{align}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "To build the training set, first, let's build one feature vector for an order with its corresponding label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "X_tr = orders_train = []\n",
    "Y_tr = labels_train = []\n",
    "for user in orders.user_id:\n",
    "    if not user.has_more_than_one_order:\n",
    "        continue\n",
    "    for order, next_order in successive pairs of user.orders:\n",
    "        if next_order is None:  # all orders except the latest one\n",
    "            continue\n",
    "        order_vector = vector of zeroes.\n",
    "        for product_id in order.products:\n",
    "            order_vector[product_id - 1] = 1 # use 0-based indexing, hence, subtract 1 from product_id for index\n",
    "        label = next_order.days_since_prior\n",
    "        X_tr.append(order_vector)\n",
    "        Y_tr.append(label)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Methods defined\n",
      "col_ind: [  195 12426 14083 ..., 28732 29486 30794]\n",
      "row_ptr: [    0     5    11 ..., 11902 11906 11914]\n",
      "Y_tr: [15 21 29 ..., 30 30 26]\n",
      "len(Y_tr)+1 == len(row_ptr):  True\n",
      "len(row_ptr):  1319\n",
      "number of orders [len(Y_tr)]:  1318\n",
      "number of line items:  11914\n",
      "Elapsed time:  0:01:06.883710\n",
      "Tests passed\n"
     ]
    }
   ],
   "source": [
    "# num_users = session.query(Order.user_id).distinct().count() # 206,209\n",
    "# order_by(Order.order_number) might not be necessary, but explicitly state it\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "from datetime import datetime\n",
    "\n",
    "def preprocess(tup):\n",
    "    if tup[1] is None:\n",
    "        second = -1\n",
    "    else:\n",
    "        second = int(tup[1])\n",
    "    return tup[0], second\n",
    "\n",
    "def n_user_ids(N):\n",
    "    return [record[0] for record in session.query(distinct(Order.user_id)).limit(N)]\n",
    "\n",
    "def n_user_ids_with_offset(N, offset):\n",
    "    return [record[0] for record in session.query(distinct(Order.user_id)) \\\n",
    "                                            .offset(offset) \\\n",
    "                                            .limit(N-offset)]\n",
    "\n",
    "def orders(user_id):\n",
    "    order_info_for_user = session.query(Order.order_id, Order.days_since_prior) \\\n",
    "            .filter(Order.user_id == user_id) \\\n",
    "            .filter(Order.order_eval_set == 'prior') \\\n",
    "            .order_by(Order.order_number) \\\n",
    "            .all()\n",
    "    return map(preprocess, order_info_for_user)\n",
    "\n",
    "def order_products(order_id):\n",
    "    return [ record[0] for record in session.query(LineItem.product_id) \\\n",
    "                                    .filter(LineItem.order_id == order_id) \\\n",
    "                                    .all() ]\n",
    "\n",
    "def product_name(product_id):\n",
    "    return session.query(Product.product_name).filter(Product.product_id == product_id).first()\n",
    "\n",
    "def build_training_data(N, offset):\n",
    "    X_tr = { \"col_ind\": [], \"row_ptr\": [] }\n",
    "    val_ind = [] # not needed because if the col_ind points to it, it's a 1\n",
    "    Y_tr = [] # days until next order\n",
    "\n",
    "    nnz = 0\n",
    "    \n",
    "    for user in n_user_ids_with_offset(N, offset):\n",
    "        user_order_info = orders(user)\n",
    "        order_ids = [ record[0] for record in user_order_info ]\n",
    "        days_since_prior = [ record[1] for record in user_order_info ]\n",
    "\n",
    "        if len(order_ids) <= 1:\n",
    "            continue\n",
    "\n",
    "        for curr_oid, days_until_next_order in zip(order_ids, days_since_prior[1:]):\n",
    "            products_in_order = order_products(curr_oid)\n",
    "\n",
    "            # product_id starts at 1. Subtract 1 to obtain the index of the product\n",
    "            # in the features vector (i.e., the column index)\n",
    "            X_tr[\"col_ind\"].extend(map(lambda pid: pid - 1, products_in_order))\n",
    "            X_tr[\"row_ptr\"].append(nnz)\n",
    "            nnz += len(products_in_order)\n",
    "            Y_tr.append(days_until_next_order)\n",
    "\n",
    "    X_tr[\"row_ptr\"].append(nnz)\n",
    "    return X_tr, Y_tr\n",
    "\n",
    "print \"Methods defined\"\n",
    "\n",
    "start_time = datetime.now()\n",
    "X_tr, Y_tr = build_training_data(N=100, offset=0)\n",
    "elapsed_time = datetime.now() - start_time\n",
    "\n",
    "with h5py.File(\"train_100_0.h5\", \"w\") as f:\n",
    "    f.create_dataset('col_ind', data=np.array(X_tr['col_ind']))\n",
    "    f.create_dataset('row_ptr', data=np.array(X_tr['row_ptr']))\n",
    "    f.create_dataset('Y_tr', data=np.array(Y_tr))\n",
    "\n",
    "with h5py.File(\"train_100_0.h5\", \"r\") as f:\n",
    "    col_ind = f[\"col_ind\"][:]\n",
    "    row_ptr = f[\"row_ptr\"][:]\n",
    "    Y_tr = f[\"Y_tr\"][:]\n",
    "    print \"col_ind: %s\" % col_ind\n",
    "    print \"row_ptr: %s\" % row_ptr\n",
    "    print \"Y_tr: %s\" % Y_tr\n",
    "    print \"len(Y_tr)+1 == len(row_ptr): \", (len(Y_tr) + 1) == len(row_ptr)\n",
    "    print \"len(row_ptr): \", len(row_ptr)\n",
    "    print \"number of orders [len(Y_tr)]: \", len(Y_tr)\n",
    "    print \"number of line items: \", len(col_ind)\n",
    "    print \"Elapsed time: \", elapsed_time\n",
    "\n",
    "X_tr, Y_tr = build_training_data(N=50, offset=0)\n",
    "with h5py.File(\"train_50_0.h5\", \"w\") as f:\n",
    "    f.create_dataset('col_ind', data=np.array(X_tr['col_ind']))\n",
    "    f.create_dataset('row_ptr', data=np.array(X_tr['row_ptr']))\n",
    "    f.create_dataset('Y_tr', data=np.array(Y_tr))\n",
    "    \n",
    "X_tr, Y_tr = build_training_data(N=100, offset=50)\n",
    "with h5py.File(\"train_100_50.h5\", \"w\") as f:\n",
    "    f.create_dataset('col_ind', data=np.array(X_tr['col_ind']))\n",
    "    f.create_dataset('row_ptr', data=np.array(X_tr['row_ptr']))\n",
    "    f.create_dataset('Y_tr', data=np.array(Y_tr))\n",
    "\n",
    "def assemble_training_data(*filenames):\n",
    "    col_ind = []\n",
    "    row_ptr = []\n",
    "    Y_tr = []\n",
    "    \n",
    "    # Initialize the CSR sparse matrix and labels\n",
    "    with h5py.File(filenames[0], 'r') as f:\n",
    "        col_ind = f[\"col_ind\"][:]\n",
    "        row_ptr = f[\"row_ptr\"][:]\n",
    "        Y_tr = f[\"Y_tr\"][:]\n",
    "        \n",
    "    for name in filenames[1:]:\n",
    "        with h5py.File(name, 'r') as f:\n",
    "            col_ind = np.concatenate((col_ind, f[\"col_ind\"][:]))\n",
    "            Y_tr = np.concatenate((Y_tr, f[\"Y_tr\"][:]))\n",
    "            next_row_ptr = f[\"row_ptr\"][:]\n",
    "            next_row_ptr = map(lambda x: x-next_row_ptr[0], next_row_ptr)\n",
    "            next_row_ptr = next_row_ptr[1:]\n",
    "            next_row_ptr = map(lambda x: x+row_ptr[-1], next_row_ptr)\n",
    "            row_ptr = np.concatenate((row_ptr, next_row_ptr))\n",
    "    return col_ind, row_ptr, Y_tr\n",
    "             \n",
    "col_ind, row_ptr, Y_tr = assemble_training_data(\"train_50_0.h5\", \"train_100_50.h5\")\n",
    "\n",
    "with h5py.File(\"train_100_0.h5\", \"r\") as f:\n",
    "    assert np.array_equal(f[\"col_ind\"][:], col_ind)\n",
    "    assert np.array_equal(f[\"Y_tr\"][:], Y_tr)\n",
    "    assert (len(Y_tr) + 1) == len(row_ptr)\n",
    "    assert np.array_equal(f[\"row_ptr\"][:], row_ptr)\n",
    "\n",
    "print \"Tests passed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
